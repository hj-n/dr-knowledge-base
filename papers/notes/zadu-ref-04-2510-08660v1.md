---
id: paper-2024-zadu-ref-04
title: "How Scale Breaks 'Normalized Stress' and KL Divergence: Rethinking Quality Metrics"
year: 2024
tags: [dr, zadu-table1-reference, dsc, kl_div, mrre, nh, nm_stress, pr, sn_stress, snc, srho, stress, tnc]
source_pdf: papers/raw/zadu-table1-references/2510.08660v1.pdf
evidence_level: medium
updated_at: 2026-02-08
---

# Problem
- —Complex, high-dimensional data is ubiquitous across many scientific disciplines, including machine learning, biology, and the social sciences.
- One of the primary methods of visualizing these datasets is with two-dimensional scatter plots that visually capture some properties of the data.

# Method Summary
- We introduce a simple technique to make both metrics scale- invariant and show that it accurately captures expected behavior on a small benchmark.
- 1 How Scale Breaks “Normalized Stress” and KL Divergence: Rethinking Quality Metrics A preliminary version of this article appeared in the BELIV 2024 workshop [67].
- One of the most commonly employed metrics, normalized stress, is sensitive to uniform scaling (stretching, shrinking) of the projection, despite this act not meaningfully changing anything about the projection.
- Another quality metric, the Kullback–Leibler (KL) divergence used in the popular t-Distributed Stochastic Neighbor Embedding (t-SNE) technique, is also susceptible to this scale sensitivity.

# When To Use / Not Use
- Use when:
  - Use when comparing embeddings under explicit scale control.
  - Use scale-invariant variants when ranking methods across plots.
- Avoid when:
  - Avoid comparing raw normalized stress or raw KL-divergence values across arbitrary scales.
- Failure modes:
  - Mis-ranking methods due to embedding-scale artifacts.

# Metrics Mentioned
- `dsc`: class consistency/separation quality in embedding (label-separation-sensitive)
- `kl_div`: distribution mismatch in neighbor probabilities
- `mrre`: rank-error behavior across neighborhood sizes
- `nh`: label-aware neighborhood agreement (label-separation-sensitive)
- `nm_stress`: non-metric stress variant
- `pr`: linear agreement of pairwise relationships
- `sn_stress`: scale-normalized stress variant
- `snc`: inter-cluster reliability via steadiness/cohesiveness
- `srho`: rank-order agreement of pairwise relationships
- `stress`: distance-fitting distortion objective/metric
- `tnc`: local neighborhood trustworthiness/continuity balance

# Implementation Notes
- Fix or optimize embedding scale before comparing stress/KL-based scores across methods.
- If labels are weakly separated in original space, down-weight label-separation-sensitive metrics in final justification.

# Claim Atoms (For Conflict Resolution)
- CLAIM-SOURCE-04-CORE | stance: support | summary: This source reports scale sensitivity of common DR quality metrics and motivates scale-aware evaluation. | evidence_ids: ZR04-E1
- CLAIM-METRIC-DSC-SOURCE-04 | stance: support | summary: This source uses or discusses `dsc` for class consistency/separation quality in embedding in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-KL_DIV-SOURCE-04 | stance: support | summary: This source uses or discusses `kl_div` for distribution mismatch in neighbor probabilities in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-MRRE-SOURCE-04 | stance: support | summary: This source uses or discusses `mrre` for rank-error behavior across neighborhood sizes in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-NH-SOURCE-04 | stance: support | summary: This source uses or discusses `nh` for label-aware neighborhood agreement in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-NM_STRESS-SOURCE-04 | stance: support | summary: This source uses or discusses `nm_stress` for non-metric stress variant in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-PR-SOURCE-04 | stance: support | summary: This source uses or discusses `pr` for linear agreement of pairwise relationships in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-SN_STRESS-SOURCE-04 | stance: support | summary: This source uses or discusses `sn_stress` for scale-normalized stress variant in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-SNC-SOURCE-04 | stance: support | summary: This source uses or discusses `snc` for inter-cluster reliability via steadiness/cohesiveness in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-SRHO-SOURCE-04 | stance: support | summary: This source uses or discusses `srho` for rank-order agreement of pairwise relationships in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-STRESS-SOURCE-04 | stance: support | summary: This source uses or discusses `stress` for distance-fitting distortion objective/metric in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2
- CLAIM-METRIC-TNC-SOURCE-04 | stance: support | summary: This source uses or discusses `tnc` for local neighborhood trustworthiness/continuity balance in dimensionality-reduction evaluation. | evidence_ids: ZR04-E2

# Workflow Relevance Map
- step: 3 | relevance: high | note: Informs task-aligned metric/technique selection and metric trust calibration.
- step: 4 | relevance: medium | note: Affects optimization objective design and score interpretation during hyperparameter search.
- step: 6 | relevance: high | note: Provides rationale that can be translated for end users.

# Evidence
- ZR04-E1 | page: 1, section: extracted, quote: "1 How Scale Breaks “Normalized Stress” and KL Divergence: Rethinking Quality Metrics A preliminary version of this article appeared in the BELIV 2024 workshop [67]."
- ZR04-E2 | page: 1, section: extracted, quote: "One of the most commonly employed metrics, normalized stress, is sensitive to uniform scaling (stretching, shrinking) of the projection, despite this act not meaningfully changing anything about the projection."
- ZR04-E3 | page: 1, section: extracted, quote: "Another quality metric, the Kullback–Leibler (KL) divergence used in the popular t-Distributed Stochastic Neighbor Embedding (t-SNE) technique, is also susceptible to this scale sensitivity."
- ZR04-E4 | page: 1, section: extracted, quote: "We investigate the effect of scaling on stress and KL divergence analytically and empirically by showing just how much the values change and how this affects dimension reduction technique evaluations."
- ZR04-E5 | page: 1, section: extracted, quote: "We introduce a simple technique to make both metrics scale- invariant and show that it accurately captures expected behavior on a small benchmark."
- ZR04-E6 | page: 1, section: extracted, quote: "Index Terms—Dimension reduction, Empirical evaluation, Stress, Kullback-Liebler Divergence."
- ZR04-E7 | page: 1, section: extracted, quote: "1 shows a simple example of how much scale can affect evaluation results of stress – by merely resizing the outputs of different techniques, one can dramatically alter the Kiran Smelser is with the University of Arizona."
- ZR04-E8 | page: 1, section: extracted, quote: "E-mail: {kaviru.gunaratne,jacob.miller,stephen.kobourov}@tum.de evaluation outcome, often leading to absurd conclusions (such as a random embedding having the lowest stress)."
- ZR04-E9 | page: 6, section: extracted, quote: "P ... is obtained through the selection of the perplexity parameter."
- ZR04-E10 | page: 11, section: extracted, quote: "We set the perplexity parameter to the value 30 ... for all datasets."
