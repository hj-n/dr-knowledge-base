---
id: paper-2022-pending-extra-s13042-021-01307-7
title: "Multi-view data clustering via non-negative matrix factorization with manifold regularization"
authors: "Ghufran Ahmad Khan, Jie Hu, Tianrui Li, Bassoma Diallo, Hongjun Wang"
venue: "International Journal of Machine Learning and Cybernetics"
year: 2022
tags: [dr, reliability, visual_analytics, reference, pending_references]
source_pdf: papers/raw/pending-references/s13042-021-01307-7.pdf
seed_note_id: "paper-2025-jeon-reliable-va-survey"
evidence_level: medium
updated_at: 2026-02-08
---

# Problem
- By using Frobenius norm, the cost function is illustrated as follows [42, 43]: However, the optimization problems are convex with respect to W† or H† separately, non-convex with W† and H† together.
- Additionally, Rai et al. [34] worked on partial multi-view data problem and affirmed a new mathematical model which contains NMF and manifold regularization factor to save the geometrical space.
- In future work, we will deal with the missing data problem by NMF and preserve the data and feature manifold structure.
- Therefore, it is difficult to calculate the global minimum.

# Method Summary
- Our contributions are stated as follows: – We propose a new multi-view clustering method based on NMF and manifold regularization, which efficiently factorize the non-negative matrix into low-rank matrix of the complementary multi-view data. – A new objective function that integrates NMF and manifold regularization is proposed.
- 684 International Journal of Machine Learning and Cybernetics (2022) 13:677–689 1 3 4.4 Baseline methods To confirm the adequacy of the proposed approach, we compare our method with some existing algorithms and cluster performances are evaluated with the emphasized evaluation metrics i.e., ACC and NMI.
- We optimize it through multiplicative update strategy to get the final clustering solution from the complementary data. – A comparable result exhibits that our approach is better for complementary multi-view data to conserve the local 679International Journal of Machine Learning and Cybernetics (2022) 13:677–689 1 3 geometrical shape of the data space than some state-ofthe-art methods.
- The average result of the DNMF, GMNMF, AMGL and MCDMF lies between 30 and 45% but our approach shows the improved clustering accuracy. – Furthermore, we incorporate the standard deviation of the proposed method and state-of-the-art method.
- Cai et al. [15] proposed a k-means based multi-view clustering method by adding the weight to various views meanwhile imposing the L2,1 norm on the objective function to reduce the impact of outliers in input data.
- 4.8 Experimental results and comparison This section incorporates the experimental results of the proposed approach with some state-of-the-art methods (baseline clustering techniques).
- Experimental analysis on the real-world datasets are exhibited that the proposed approach achieves better clustering performance than some state-of-the-art algorithms.

# When To Use / Not Use
- Use when:
  - ACC is calculated as: where /u1D706(x, y) is the indicator function, n describes the total number of objects, and map(ci ) defines the mapping function, which is used to evaluate the similarity between the achieved cluster labels and the ground truth labels. – NMI: is used for shared statistics between truth labels of the dataset and the acquired label from the proposed algorithm.
  - The semi-NMF is used for the semantic structure of multi-view data in multi-layer (23)NMI = c∑ u=1 k∑ v=1 log(nnuv nun� v ) ���� � c∑ u=1 nu log nu n �� k∑ v=1 n� v log n� v n � fashion, and intrinsic structure is applied to get output from the deep structure of data.
- Avoid when:
  - 1 An example of MCNMF on a toy dataset 683International Journal of Machine Learning and Cybernetics (2022) 13:677–689 1 3 The difference between the consensus coefficient matrix and coefficient matrix is used to find the disagreement term between the various views.
  - 4.5 Parameter study There are three parameters are used in the proposed method, i.e., p , /u1D707 , and r, for the nearest neighbor, regularization parameter, and control the weight distribution of each view, respectively.
- Failure modes:
  - 4.2 Experiments on real datasets We use seven real-world datasets, i.e., BBC Sport 1, BBC2, 3Sources3, Newsgroups (NGs)4, Wikipedia Articles 5, Reuters6, and Texas7, to endorse the superiority of the proposed approach.

# Metrics Mentioned
- `neighborhood-preservation criteria`: referenced as part of projection-quality or reliability assessment.
- `rank-based quality criteria`: referenced as part of projection-quality or reliability assessment.

# Implementation Notes
- For the optimization of the proposed MCNMF, we enfold the iterative strategy to update the parameter in MCNMF.
- In short, by joining the two sections, the complexity for optimization of the proposed method for M views are O(rMDN), where r, M, D, and N represent the lowrank of matrix, the number of views, the number of features, and the number of data points, respectively.
- It gets the attention that when the volume of iteration increases, the values of objective function drop sharply, and convergence is accomplished after 20 iterations, and the clustering performance becomes stable after convergence is achieved.
- It takes out the latent structure of the data without considering the label of the dataset. – Auto-weighted multiple graph learning (AMGL) [49]: It efficiently learns the weight for every view automatically without adding any extra parameter.
- 4.5 Parameter study There are three parameters are used in the proposed method, i.e., p , /u1D707 , and r, for the nearest neighbor, regularization parameter, and control the weight distribution of each view, respectively.
- Keep preprocessing, initialization policy, and seed protocol fixed when comparing methods or parameter settings.

# Claim Atoms (For Conflict Resolution)
- CLAIM-PENDING-EXTRA-C1 | stance: support | summary: By using Frobenius norm, the cost function is illustrated as follows [42, 43]: However, the optimization problems are convex with respect to W† or H† separately, non-convex with W† and H† together. | evidence_ids: PENDING-EXTRA-E1, PENDING-EXTRA-E2
- CLAIM-PENDING-EXTRA-C2 | stance: support | summary: Our contributions are stated as follows: – We propose a new multi-view clustering method based on NMF and manifold regularization, which efficiently factorize the non-negative matrix into low-rank matrix of the complementary multi-view data. – A new objective function that integrates NMF and manifold regularization is proposed. | evidence_ids: PENDING-EXTRA-E3, PENDING-EXTRA-E4
- CLAIM-PENDING-EXTRA-C3 | stance: support | summary: For the optimization of the proposed MCNMF, we enfold the iterative strategy to update the parameter in MCNMF. | evidence_ids: PENDING-EXTRA-E5, PENDING-EXTRA-E6

# Workflow Relevance Map
- step: 1 | relevance: medium | note: supports explicit task clarification before DR recommendation
- step: 2 | relevance: medium | note: adds preprocessing/data-condition constraints for reliable comparison
- step: 3 | relevance: high | note: directly informs task-aligned method and metric selection
- step: 5 | relevance: high | note: provides hyperparameter sensitivity/optimization guidance

# Evidence
- PENDING-EXTRA-E1 | page: 3, section: extracted, quote: "By using Frobenius norm, the cost function is illustrated as follows [42, 43]: However, the optimization problems are convex with respect to W† or H† separately, non-convex with W† and H† together."
- PENDING-EXTRA-E2 | page: 2, section: extracted, quote: "Additionally, Rai et al. [34] worked on partial multi-view data problem and affirmed a new mathematical model which contains NMF and manifold regularization factor to save the geometrical space."
- PENDING-EXTRA-E3 | page: 12, section: extracted, quote: "In future work, we will deal with the missing data problem by NMF and preserve the data and feature manifold structure."
- PENDING-EXTRA-E4 | page: 4, section: extracted, quote: "Therefore, it is difficult to calculate the global minimum."
- PENDING-EXTRA-E5 | page: 2, section: extracted, quote: "Our contributions are stated as follows: – We propose a new multi-view clustering method based on NMF and manifold regularization, which efficiently factorize the non-negative matrix into low-rank matrix of the complementary multi-view data. – A new objective function that integrates NMF and manifold regularization is proposed."
- PENDING-EXTRA-E6 | page: 8, section: extracted, quote: "684 International Journal of Machine Learning and Cybernetics (2022) 13:677–689 1 3 4.4 Baseline methods To confirm the adequacy of the proposed approach, we compare our method with some existing algorithms and cluster performances are evaluated with the emphasized evaluation metrics i.e., ACC and NMI."
- PENDING-EXTRA-E7 | page: 2, section: extracted, quote: "We optimize it through multiplicative update strategy to get the final clustering solution from the complementary data. – A comparable result exhibits that our approach is better for complementary multi-view data to conserve the local 679International Journal of Machine Learning and Cybernetics (2022) 13:677–689 1 3 geometrical shape of the data space than some state-ofthe-art methods."
- PENDING-EXTRA-E8 | page: 10, section: extracted, quote: "The average result of the DNMF, GMNMF, AMGL and MCDMF lies between 30 and 45% but our approach shows the improved clustering accuracy. – Furthermore, we incorporate the standard deviation of the proposed method and state-of-the-art method."
