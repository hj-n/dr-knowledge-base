---
id: paper-2014-pending-extra-1403-0700v1
title: "Random projections on manifolds of Symmetric Positive Definite matrices for image classification"
authors: "Azadeh Alavi, Arnold Wiliem, Kun Zhao, Brian C. Lovell, Conrad Sanderson"
venue: "IEEE Winter Conference on Applications of Computer Vision"
year: 2014
tags: [dr, reliability, visual_analytics, reference, pending_references]
source_pdf: papers/raw/pending-references/1403.0700v1.pdf
seed_note_id: "paper-2025-jeon-reliable-va-survey"
evidence_level: medium
updated_at: 2026-02-08
---

# Problem
- According to the Johnson-Lindenstrauss lemma [1], it is possible to map a set of high-dimensional points into much lower dimensional space wherein the pairwise distance between two points are well-preserved: Lemma 3.1.
- Despite its properties, learning methods using this approach have to deal with computational challenges, such as employing computationally expensive non-linear operators.
- Working directly on the manifold space via AIRM poses many computational challenges.

# Method Summary
- We compare our proposed method, here denoted as Random Projection On SPD manifold for Imag E Classiﬁcation (ROSE), with several other embedding approaches (tangent spaces, RKHS and hashing) as well as several state-of-the-art methods.
- Random Projection Space Discriminability We ﬁrst compare the performance of the proposed ROSE method with several other embedding methods: (1) Kernel SVM (KSVM) using the Stein divergence kernel, (2) Kernelised Locality-Sensitive Hashing (KLSH) [19], and (3) Riemannian Spectral Hashing (RSH), a hashing method speciﬁcally designed for smooth manifolds [6].
- Experiments on face recognition, person reidentiﬁcation and texture classiﬁcation show that the proposed method (combined with a linear SVM) outperforms state-of-the-art approaches such as Tensor Sparse Coding, Histogram Plus Epitome, Riemannian Locality Preserving Projection and Relational Divergence Classiﬁcation.
- Experiments on face recognition, person re-identiﬁcation and texture classiﬁcation show that the proposed approach outperforms several recent methods, such as Tensor Sparse Coding, Histogram Plus Epitome, Riemannian Locality Preserving Projection and Relational Divergence Classiﬁcation.
- To overcome this limitation, we propose to use generated synthetic SPD matrices X1,..., Xn∈Symd + centred around the mean of the data (denoted by Xµ), where the mean of the training set can be determined intrinsically via the Karcher mean algorithm [22].
- Random Projection on RKHS We aim to address classiﬁcation tasks, originally formulated on the manifold, by embedding them into a random projection space, which can be considered as Euclidean, while still honouring the manifold geometry structure.
- The main idea of our proposed approach, denoted as Random Projection On SPD manifold for Imag E Classiﬁcation (ROSE), is to ﬁrst map all points on the manifold into RKHS, with implicit mapping function φ(·), via the Stein divergence kernel.

# When To Use / Not Use
- Use when:
  - To overcome this limitation, we propose to use generated synthetic SPD matrices X1,..., Xn∈Symd + centred around the mean of the data (denoted by Xµ), where the mean of the training set can be determined intrinsically via the Karcher mean algorithm [22].
  - Random Projection Space Discriminability We ﬁrst compare the performance of the proposed ROSE method with several other embedding methods: (1) Kernel SVM (KSVM) using the Stein divergence kernel, (2) Kernelised Locality-Sensitive Hashing (KLSH) [19], and (3) Riemannian Spectral Hashing (RSH), a hashing method speciﬁcally designed for smooth manifolds [6].
- Avoid when:
  - Bottom row: examples of closely-cropped faces from the FERET ‘b’ subset [23]. fed to a linear Support Vector Machine classiﬁer, which uses a one-versus-all conﬁguration for multi-class classiﬁcation [10, 30] The parameter settings are as follows.
  - We show that the arXiv:1403.0700v1 [cs.CV] 4 Mar 2014 space is only as effective as the completeness of the training data generating the random projection hyperplanes, and address this through the use of synthetic data to augment training data.
- Failure modes:
  - Hence the complexity of classiﬁcation for a single query data is equal to O(p3 +pt +nb) which is more efﬁcient than Relational Divergence based Classication (RDC) [2], which is later shown to be the second best approach in the experiment part.

# Metrics Mentioned
- `neighborhood-preservation criteria`: referenced as part of projection-quality or reliability assessment.

# Implementation Notes
- Bottom row: examples of closely-cropped faces from the FERET ‘b’ subset [23]. fed to a linear Support Vector Machine classiﬁer, which uses a one-versus-all conﬁguration for multi-class classiﬁcation [10, 30] The parameter settings are as follows.
- Random Projection Space Discriminability We ﬁrst compare the performance of the proposed ROSE method with several other embedding methods: (1) Kernel SVM (KSVM) using the Stein divergence kernel, (2) Kernelised Locality-Sensitive Hashing (KLSH) [19], and (3) Riemannian Spectral Hashing (RSH), a hashing method speciﬁcally designed for smooth manifolds [6].
- Experiments on face recognition, person reidentiﬁcation and texture classiﬁcation show that the proposed method (combined with a linear SVM) outperforms state-of-the-art approaches such as Tensor Sparse Coding, Histogram Plus Epitome, Riemannian Locality Preserving Projection and Relational Divergence Classiﬁcation.
- Experiments on face recognition, person re-identiﬁcation and texture classiﬁcation show that the proposed approach outperforms several recent methods, such as Tensor Sparse Coding, Histogram Plus Epitome, Riemannian Locality Preserving Projection and Relational Divergence Classiﬁcation.
- To overcome this limitation, we propose to use generated synthetic SPD matrices X1,..., Xn∈Symd + centred around the mean of the data (denoted by Xµ), where the mean of the training set can be determined intrinsically via the Karcher mean algorithm [22].
- Keep preprocessing, initialization policy, and seed protocol fixed when comparing methods or parameter settings.

# Claim Atoms (For Conflict Resolution)
- CLAIM-PENDING-EXTRA-C1 | stance: support | summary: According to the Johnson-Lindenstrauss lemma [1], it is possible to map a set of high-dimensional points into much lower dimensional space wherein the pairwise distance between two points are well-preserved: Lemma 3.1. | evidence_ids: PENDING-EXTRA-E1, PENDING-EXTRA-E2
- CLAIM-PENDING-EXTRA-C2 | stance: support | summary: We compare our proposed method, here denoted as Random Projection On SPD manifold for Imag E Classiﬁcation (ROSE), with several other embedding approaches (tangent spaces, RKHS and hashing) as well as several state-of-the-art methods. | evidence_ids: PENDING-EXTRA-E3, PENDING-EXTRA-E4
- CLAIM-PENDING-EXTRA-C3 | stance: support | summary: Bottom row: examples of closely-cropped faces from the FERET ‘b’ subset [23]. fed to a linear Support Vector Machine classiﬁer, which uses a one-versus-all conﬁguration for multi-class classiﬁcation [10, 30] The parameter settings are as follows. | evidence_ids: PENDING-EXTRA-E5, PENDING-EXTRA-E6

# Workflow Relevance Map
- step: 1 | relevance: medium | note: supports explicit task clarification before DR recommendation
- step: 3 | relevance: high | note: directly informs task-aligned method and metric selection
- step: 5 | relevance: high | note: provides hyperparameter sensitivity/optimization guidance
- step: 6 | relevance: high | note: guides reliable interpretation of projected views

# Evidence
- PENDING-EXTRA-E1 | page: 2, section: extracted, quote: "According to the Johnson-Lindenstrauss lemma [1], it is possible to map a set of high-dimensional points into much lower dimensional space wherein the pairwise distance between two points are well-preserved: Lemma 3.1."
- PENDING-EXTRA-E2 | page: 1, section: extracted, quote: "Despite its properties, learning methods using this approach have to deal with computational challenges, such as employing computationally expensive non-linear operators."
- PENDING-EXTRA-E3 | page: 7, section: extracted, quote: "Working directly on the manifold space via AIRM poses many computational challenges."
- PENDING-EXTRA-E4 | page: 4, section: extracted, quote: "We compare our proposed method, here denoted as Random Projection On SPD manifold for Imag E Classiﬁcation (ROSE), with several other embedding approaches (tangent spaces, RKHS and hashing) as well as several state-of-the-art methods."
- PENDING-EXTRA-E5 | page: 5, section: extracted, quote: "Random Projection Space Discriminability We ﬁrst compare the performance of the proposed ROSE method with several other embedding methods: (1) Kernel SVM (KSVM) using the Stein divergence kernel, (2) Kernelised Locality-Sensitive Hashing (KLSH) [19], and (3) Riemannian Spectral Hashing (RSH), a hashing method speciﬁcally designed for smooth manifolds [6]."
- PENDING-EXTRA-E6 | page: 7, section: extracted, quote: "Experiments on face recognition, person reidentiﬁcation and texture classiﬁcation show that the proposed method (combined with a linear SVM) outperforms state-of-the-art approaches such as Tensor Sparse Coding, Histogram Plus Epitome, Riemannian Locality Preserving Projection and Relational Divergence Classiﬁcation."
- PENDING-EXTRA-E7 | page: 1, section: extracted, quote: "Experiments on face recognition, person re-identiﬁcation and texture classiﬁcation show that the proposed approach outperforms several recent methods, such as Tensor Sparse Coding, Histogram Plus Epitome, Riemannian Locality Preserving Projection and Relational Divergence Classiﬁcation."
- PENDING-EXTRA-E8 | page: 3, section: extracted, quote: "To overcome this limitation, we propose to use generated synthetic SPD matrices X1,..., Xn∈Symd + centred around the mean of the data (denoted by Xµ), where the mean of the training set can be determined intrinsically via the Karcher mean algorithm [22]."
